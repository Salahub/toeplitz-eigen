%======================================================================
%   D O C U M E N T   P R E A M B L E
% Specify the document class, default style attributes, and page dimensions, etc.
% For hyperlinked PDF, suitable for viewing on a computer, use this:
\documentclass[letterpaper,12pt,oneside,final]{article}

\newcommand{\package}[1]{\textbf{#1}} % package names in bold text
\newcommand{\cmmd}[1]{\textbackslash\texttt{#1}} % command name in tt font 
\usepackage{amsmath,amssymb,amstext} % Lots of math symbols and environments
\usepackage[pdftex]{graphicx} % For including graphics N.B. pdftex graphics driver
\usepackage{amsmath,amssymb,amstext,amsthm,amsfonts}
\usepackage{dsfont}
\usepackage[pdftex]{graphicx}
\usepackage{caption}
\usepackage{color}% Include colors for document elements
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{float}
\usepackage{multirow}
\usepackage{algorithm} % For counting chapters
\usepackage{algorithmicx, algpseudocode}
\usepackage[pdftex,pagebackref=false]{hyperref} % with basic options

\definecolor{background-color}{gray}{0.98}
\definecolor{steelblue}{rgb}{0.27, 0.51, 0.71}
\definecolor{brickred}{rgb}{0.8, 0.25, 0.33}
\definecolor{bluegray}{rgb}{0.4, 0.6, 0.8}
\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}

\hypersetup{
    plainpages=false,       % needed if Roman numbers in frontpages
    unicode=false,          % non-Latin characters in Acrobat's bookmarks
    pdftoolbar=true,        % show Acrobats toolbar?
    pdfmenubar=true,        % show Acrobat's menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Structured\ approximation},    % title
    pdfauthor={C. Salahub, J. Uhlmann},    % author
    pdfsubject={Statistics},  % subject
%    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=steelblue,         % color of internal links
    citecolor=brickred,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

% Page margins
\setlength{\marginparwidth}{0pt} % width of margin notes
\setlength{\marginparsep}{0pt} % width of space between body text and margin notes
\setlength{\evensidemargin}{0.125in} % Adds 1/8 in. to binding side of all even pages when "twoside" is selected
\setlength{\oddsidemargin}{0.125in} % Adds 1/8 in. to the left of all pages when "oneside" is selected,
                                    % and to the left of all odd pages when "twoside" is selected
\setlength{\textwidth}{6.375in} % assuming US letter paper (8.5 in. x 11 in.) and margins as above
\raggedbottom

\setlength{\parskip}{\medskipamount} % space between paragraphs
\renewcommand{\baselinestretch}{1} % line space setting

% Commands
% Code
\newcommand{\code}[1]{\texttt{#1}}
\newcommand*{\Rnsp}{\textsf{R}}
\newcommand*{\R}{\textsf{R}$~$}
\newcommand*{\Pythonnsp}{\textsf{Python}}
\newcommand*{\Python}{\textsf{Python}$~$}
\newcommand{\pkg}[1]{\textsf{#1}}
\newcommand{\pkgsp}[1]{\textsf{#1}$~$}
\algblock{Input}{EndInput}
\algnotext{EndInput}
\newcommand{\Desc}[2]{\State \makebox[2em][l]{#1}#2}

% Theorem styles
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

% vectors
\newcommand{\ve}[1]{\mathbf{#1}}           % for vectors
\newcommand{\sv}[1]{\boldsymbol{#1}}   % for greek letters
\newcommand{\m}[1]{\mathbf{#1}}               % for matrices
\newcommand{\sm}[1]{\boldsymbol{#1}}   % for greek letters
\newcommand{\tr}[1]{{#1}^{\mkern-1.5mu\mathsf{T}}}              % for transpose
\newcommand{\conj}[1]{{#1}^{\ast}}
\newcommand{\norm}[1]{||{#1}||}              % norm
\newcommand{\frob}[1]{\norm{#1}_F}
\newcommand{\abs}[1]{\lvert{#1}\rvert}              % norm
\newcommand*{\mvec}{\operatorname{vec}}
\newcommand*{\trace}{\operatorname{trace}}
\newcommand*{\rank}{\operatorname{rank}}
\newcommand*{\diag}{\operatorname{diag}}
\newcommand*{\vspan}{\operatorname{span}}
\newcommand*{\rowsp}{\operatorname{rowsp}}
\newcommand*{\colsp}{\operatorname{colsp}}
\newcommand*{\svd}{\operatorname{svd}}
\newcommand*{\edm}{\operatorname{edm}}  % euclidean distance matrix (D * D)
\newcommand{\oneblock}[3]{\m{B}_{#1:#2:#3}}
\newcommand{\stripe}[2]{\m{S}_{#1,#2}}

% contingency tables
\newcommand{\abdiff}{\delta_{AB}}

% statistical
\newcommand{\widebar}[1]{\overline{#1}}  
\newcommand{\wig}[1]{\tilde{#1}}  
\newcommand{\bigwig}[1]{\widetilde{#1}}  
\newcommand{\follows}{\sim}  
\newcommand{\leftgiven}{~\left\lvert~}
\newcommand{\given}{~\vert~}
\newcommand{\biggiven}{~\vline~}
\newcommand{\indep}{\bot\hspace{-.6em}\bot}
\newcommand{\notindep}{\bot\hspace{-.6em}\bot\hspace{-0.75em}/\hspace{.4em}}
\newcommand{\depend}{\Join}
\newcommand{\notdepend}{\Join\hspace{-0.9 em}/\hspace{.4em}}
\newcommand{\imply}{\Longrightarrow}
\newcommand{\notimply}{\Longrightarrow \hspace{-1.5em}/ \hspace{0.8em}}
\newcommand{\xyAssociation}{g}
\newcommand{\xDomain}{\mathcal{X}}
\newcommand{\yDomain}{\mathcal{Y}}
\newcommand{\measureRange}{\mathcal{R}}
\newcommand{\bigChi}{\mathcal{D}}
\newcommand{\ind}[2]{I_{#2} \left( #1 \right)}
%\newcommand{\ind}[1]{\mathds{1} \hspace{-0.1cm}\left( #1 \right)}
\newcommand{\mutInf}{\mathcal{I}}
 
% operators
\newcommand{\Had}{\circ}
\newcommand{\measureAssociation}{G}
\DeclareMathOperator*{\lmin}{Minimize}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\arginf}{arg\,inf}
\DeclareMathOperator*{\argsup}{arg\,sup}

% Sets
\newcommand*{\intersect}{\cap}
\newcommand*{\union}{\cup}
\let\oldemptyset\emptyset
\let\emptyset\varnothing

% Fields, Reals, etc. etc
\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\Reals}{\field{R}}
\newcommand{\Integers}{\field{Z}}
\newcommand{\Naturals}{\field{N}}
\newcommand{\Complex}{\field{C}}
\newcommand{\Rationals}{\field{Q}}

% Editorial
\newcommand{\needtocite}[1]{{\color{red} [Need to cite {#1} here]}}
\newcommand{\comment}[1]{{\color{steelblue} COMMENT:  {#1}}}
\newcommand{\TODO}[1]{{\color{brickred} TODO:  {#1}}}

\title{Frobenius-optimal approximation by structured matrices.}
\author{Chris Salahub \\ {\footnotesize University of Waterloo,
    \texttt{csalahub@uwaterloo.ca}} \\
Jeffrey Uhlmann \\ {\footnotesize University of Missouri, \texttt{uhlmannj@missouri.edu}}}

\begin{document}

\maketitle

\begin{abstract}
  The approximation of a general matrix $\m{M}$ by a structured matrix $\m{T}$ is shown to be optimized in the Frobenius norm by structured means. It is proven that the optimal value of the Frobenius norm is then given by the total standard deviation of entries in $\m{M}$ from the structured means. This approximation is demonstrated for several examples of structured matrices including circulant, Toeplitz, and Hankel matrices, and the consequences of these facts are explored.
\end{abstract}

\section{Introduction}

Suppose we would like to approximate the $n \times n$ matrix
\begin{equation} \label{eq:Mdefn}
  \m{M} = \begin{bmatrix}
    m_{00} & m_{01} & \dots & m_{0,n-1} \\
    m_{10} & m_{11} & \dots & m_{1,n-1} \\
    \vdots & \vdots & \ddots & \vdots \\
    m_{n-1,0} & m_{n-1,1} & \dots & m_{n-1,n-1}
  \end{bmatrix}
\end{equation}
with entries $m_{ij} \in \Complex$ using a structured matrix $\m{T} \in \Complex^{n \times n}$ for computational or analytical reasons. Examples include circulant $\m{T}$ for preconditioning \cite{chan1988optimal, venkatapathi2021circulant} and Toeplitz-Hankel $\m{T}$ for physical modelling \cite{narayanshastry2021toeplitz}. For any application, we prefer the approximating matrix $\m{T}$ to be optimal by some measure.

One common measure used to evaluate a matrix approximation is the Frobenius norm. For a matrix $\m{M}$ approximated by $\m{T}$, the Frobenius norm of the difference $\m{T} - \m{M}$ is defined as
\begin{equation} \label{eq:frobnorm}
  \frob{\m{T} - \m{M}} = \sqrt{\trace \left ( \conj{(\m{T} - \m{M})}(\m{T} - \m{M}) \right )},
\end{equation}
where $\conj{\m{A}}$ is the conjugate matrix of $\m{A} \in \Complex^{n \times n}$. Minimizing this metric was the express goal of the preconditioner derived in \cite{chan1988optimal} and was noted as a positive feature of the approximation of \cite{venkatapathi2021circulant}. Both of these approximations use a circulant $\m{T}$, however. This work presents a far more general result which can be applied to \emph{any} structural matrix.

\section{Structured matrices} \label{sec:struc}

We begin with a formal definition.

\begin{definition}[Structured matrix] \label{def:strucMat}
  Suppose we have a matrix $\m{T}$ with entries $t_{ij}$ following a regular pattern in $i$ and $j$, that is
  \begin{equation} \label{eq:generalStruc}
    t_{ij} = t_{f(i,j)}
  \end{equation}
  where $f:\{0,1, \dots, n-1\}^2 \mapsto \{0, 1, 2, \dots, K\}$ is the index function defining the membership of the index pair $i,j$ to an index set with a constant value. Then we say that $\m{T}$ is \emph{structured}. Additionally, define the $k^{\text{th}}$ index set
  $$\mathcal{T}_k = \{(i,j) | f(i,j) = k\}$$
  with cardinality $\lvert \mathcal{T}_k \rvert = n_k > 0$.
\end{definition}

In this definition, the index function $f(\cdot,\cdot)$ defines the structure of $\m{T}$ by indicating which elements of $\m{T}$ are equal. Changing $f$ results in a differently structured $\m{T}$. Some common structures and the corresponding functions are shown in Table \ref{tab:indexfuns}. These functions are not unique; many candidate functions define identical index sets. Hankel matrices, for example, can take either $f(i,j) = j + i$ or $f(i,j) = 2(n-1) - j - i$.

\begin{table}
  \begin{center}
  \begin{tabular} {|c|c|} \hline
    Structure & $f(i,j)$ \\ \hline
    Circulant & $(i - j) \bmod n$ \\
    Toeplitz & $j - i + n$ \\
    Hankel & $i + j$ \\ \hline
  \end{tabular}
  \caption{Some common examples of structured index functions.} \label{tab:indexfuns}
  \end{center}
\end{table}

Noting that a piecewise constant $f(i,j)$ can be defined for arbitrary index sets, it is obvious that the structures which can be defined are not limited to the simple functions in Table \ref{tab:indexfuns}. Indeed, the range of potential matrices described by Definition \ref{def:strucMat} goes from the unstructured case where
$$f(i,j) = in + j$$
to a matrix with one repeated constant value when
$$f(i,j) = 0.$$
Between these exremes any structure can be described with different index functions.

\subsection{Optimizing the Frobenius norm} \label{sec:approx}

The preliminaries above lead to the following proof.

\begin{theorem}[Means minimize the structured approximation of $\m{M}$ in the Frobenius norm.] \label{thm:genOptimal}
  The optimal structured matrix $\m{T}$ with index function $f(i,j)$ and index sets $\mathcal{T}_0, \mathcal{T}_1, \dots, \mathcal{T}_K$ to approximate $\m{M}$ is given by the matrix $\m{T}_M$ with
  \begin{equation} \label{eq:meanStrucMat}
    t_{ij} = t_{f(i,j)} = \widebar{m}_{f(i,j)}
  \end{equation}
  where
  \begin{equation} \label{eq:strucMeans}
    \widebar{m}_k := \frac{1}{n_k} \sum_{\mathcal{T}_k} m_{ij}.
  \end{equation}
  is the mean of entries of $\m{M}$ over the corresponding index set. Furthermore, $\frac{1}{\sqrt{n}}\frob{\m{T}_M - \m{M}}$ is the total within-group standard deviation of the values of $\m{M}$ over all index sets.
\end{theorem}
\begin{proof}
   Take $\widebar{m}_k$ to be the mean of entries in $\m{M}$ for the $k^{\text{th}}$ index set as in Equation \ref{eq:strucMeans}, define the vector of all such means
  \begin{equation*}
    \widebar{ \ve{m} } = \tr{ (\widebar{m}_0, \widebar{m}_1, \dots, \widebar{m}_K) }.
  \end{equation*}
  Further, denote the vector of unique $t_k$ as
  \begin{equation*}
    \ve{t} = \tr{ ( t_0, t_1, \dots, t_K ) }
  \end{equation*}
  and the diagonal matrix of $n_k$ as
  \begin{equation*}
    \m{N} = \diag (n_0, n_1, \dots, n_K).
  \end{equation*}
  Noting that Equation \ref{eq:frobnorm} is always positive, any $\m{T}$ which minimizes the Frobenius norm will also minimize the squared Frobenius norm of the difference:
  $$\frob{\m{T} - \m{M}}^2,$$
  that is
  \begin{equation} \label{eq:ToBeOptimized}
    \trace \left ( \conj{(\m{T} - \m{M})}(\m{T} - \m{M}) \right ) = \trace \conj{\m{M}} \m{M} - \trace \conj{\m{M}} \m{T} - \trace \conj{\m{T}} \m{M} + \trace \conj{\m{T}} \m{T}.
  \end{equation}
  $\conj{\m{M}} \m{M}$ is constant in $\m{T}$, so this term can be ignored in the optimization. The latter three terms can be considered individually to express them in terms of the $t_k$. $\trace \conj{\m{T}} \m{T}$ is the simplest, as
  \begin{equation} \label{eq:Tsquared}
    \trace \conj{\m{T}} \m{T} = \sum_{i = 0}^{n-1} \sum_{j = 0}^{n-1} \conj{t}_{ij} t_{ij} = \sum_{k = 0}^{K} n_k \conj{t}_k t_k.
  \end{equation}
  The negative terms can be expressed
  \begin{equation} \label{eq:conjMT}
    \trace \conj{\m{M}} \m{T} = \sum_{i = 0}^{n-1} \sum_{j = 0}^{n-1} \conj{m}_{ji} t_{ij} = \sum_{k = 0}^{K} n_k t_k \conj{ \widebar{m} }_k 
  \end{equation}
  and
  \begin{equation} \label{eq:conjTM}
    \trace \conj{\m{T}} \m{M} = \sum_{k = 0}^{K} n_k \conj{t}_k \widebar{m}_k.
  \end{equation}
  So we seek to minimize
  \begin{equation*}
    F(\ve{t}) = \sum_{k = 0}^{K} n_k \conj{t}_k t_k - \sum_{k = 0}^{K} n_k \conj{t}_k \widebar{m}_k - \sum_{k = 0}^{K} n_k t_k \conj{ \widebar{m} }_k,
  \end{equation*}
  which we can write in matrix form as
  \begin{eqnarray}
    F(\ve{t}) & = & \conj{ \ve{t} } \m{N} \ve{t} - \conj{ \ve{t} } \m{N} \widebar{ \ve{m} } - \conj{ \widebar { \ve{m} } } \m{N} \ve{t} \nonumber \\
              & = & \conj{ \left ( \ve{t} - \widebar{ \ve{m} } \right ) } \m{N}  \left ( \ve{t} - \widebar{ \ve{m} } \right ) - \conj{ \widebar{ \ve{m} } } \m{N} \widebar{ \ve{m} }.
  \end{eqnarray}
  As $n_k > 0$ for all $k = 0, 1, \dots, K$, $\m{N}$ is positive definite, and so the quadratic form $\conj{ \ve{x} } \m{N} \ve{x}$ has a minimum of zero when $\ve{x} = \ve{0}$. Therefore $F(\ve{t})$ is minimized for $\ve{t} = \widebar{ \ve{ m } }$ and has a minimum of
  \begin{equation} \label{eq:Fmin}
    F(\widebar{ \ve{m} }) = - \conj{ \widebar{ \ve{m} } } \m{N} \widebar{ \ve{m} } = - \sum_{k = 0}^K n_k \norm{\widebar{m}_k}^2.
  \end{equation}
  So $\m{T}_M$ is the Frobenius-optimal structured matrix $\m{T}$ approximating $\m{M}$. The residual $\m{T}_M - \m{M}$ has a squared Frobenius norm of
  \begin{eqnarray}
    \frob{\m{T}_M - \m{M}}^2 & = & \sum_{k = 0}^K \sum_{\mathcal{T}_k} \norm{m_{ij}}^2 - \sum_{k = 0}^K n_k \norm{\widebar{m}_k}^2 \nonumber \\
                             & = & \sum_{k = 0}^K n_k \left ( \sum_{\mathcal{T}_k} \frac{\norm{m_{ij}}^2}{n_k} - \norm{\widebar{m}_k}^2  \right ) \nonumber \\
                             & = & \sum_{k = 0}^K n_k \sigma_k^2 \label{eq:TMmin}
  \end{eqnarray}
  where
  $$\sigma_k^2 = \frac{1}{n_k} \sum_{\mathcal{T}_k} \left ( m_{ij} - \widebar{m}_k \right ) ^2$$
  is the variance of the $m_{ij}$ for the index set $\mathcal{T}_k$. Therefore we have
  \begin{equation*}
    \frac{1}{\sqrt{n}}\frob{\m{T}_M - \m{M}} = \sum_{k = 0}^K \frac{n_k}{n} \sigma_k^2,
  \end{equation*}
  which is the within-group standard deviation in, for example, typical ANOVA.
\end{proof}

\TODO{Any statistical ideas we might incorporate here? We can immediately generalize this to the $L_{1,1}$ norm with the median, for example. Is there any point in trying to develop some ANOVA-on-matrices as a procedure?}

\TODO{Expand on the utility of this for random matrices of a known structure, for example in genetics \cite{salahub2022structural}}

\section{Examples} \label{sec:examples}

This section shows the application of the proof contained in Section \ref{sec:approx} to some common structural matrices, starting with an interesting equivalence in the circulant case.

\subsection{Circulant matrices}

Circulant matrices have an index function
\begin{equation} \label{eq:circdefn}
  f(i,j) = (i - j) \bmod n
\end{equation}
and so contain $n$ unique values denoted $t_0, t_1, \dots, t_{n-1} \in \Complex$. They see widespread use in signal processing, computation, and physical modelling both due to their close relationship with the Fourier transform and their known eigensystem \cite{chan1988optimal,gray2006toeplitz,narayanshastry2021toeplitz}. The general circulant eigenvalues $\lambda_k$ for $k = 0, 1, \dots, n-1$ are given by
\begin{equation} \label{eq:circevals}
  \lambda_k = t_0 + \sum_{l = 1}^{n-1} t_l \omega^{lk}
\end{equation}
and the corresponding $k^{\text{th}}$ eigenvector is given by
\begin{equation} \label{eq:circevecs}
  \ve{x}_k = \tr{(1, \omega^k, \omega^{2k}, \dots, \omega^{(M-1)k} )}
\end{equation}
where $\omega = \exp (\frac{2 \pi i}{n})$ is the complex $n^{\text{th}}$ root of unity and $i = \sqrt{-1}$.

Much of the utility of circulant matrices arises from this eigensystem. The $n \times n$ matrix of eigenvectors of $\m{C}$ scaled to be unitary,
\begin{equation} \label{eq:DFT}
  \m{F} = \frac{1}{\sqrt{n}} [\ve{x}_0 | \ve{x}_1 | \ve{x}_2 | \dots | \ve{x}_{n-1} ] = \tr{\m{F}},
\end{equation}
is simply the discrete Fourier transform (DFT). Circulant matrices therefore have a deep relationship with real and complex analysis \cite{grenanderszego1958}. Importantly, the discrete Fourier transform provides an alternate route to compute the structural means in the circulant case.

Consider the simple approximation algorithm:
\begin{algorithm}
  \caption{Optimal circulant approximation}
  \label{algo:circ}
  \begin{algorithmic}
    \Input
    \State$\m{M}$ - an arbitrary $n \times n$ matrix
    \EndInput
    \Statex
    \State \textbf{construct} $\m{D} \longleftarrow \diag \left ( \m{F} \m{M} \conj{\m{F}} \right )$
    \State \Return{$\m{C}_D = \conj{\m{F}} \m{D} \m{F}$}
  \end{algorithmic}
\end{algorithm}
%\begin{enumerate}
%\item construct the diagonal matrix $\m{D}$ where $d_{jj} = (\m{F} \m{M} \conj{\m{F}})_{jj}$ and $\conj{\m{F}}$ is the complex conjugate of $\m{F}$,
%\item compute $\m{C}_{D} = \conj{\m{F}} \m{D} \m{F}$.
%\end{enumerate}
As $\m{D}$ is diagonal and $\m{F}$ is the matrix of eigenvectors for any circulant matrix, $\m{C}_{D}$ is a circulant matrix with eigenvalues given by $d_{jj}$, the diagonal values of $\m{D}$. To determine the elements $(\m{C}_{D})_{ij}$ in terms of $\omega$, $\ve{x}$, and $\m{M}$, first note
\begin{equation} \label{eq:Dexplicit}
  d_{jj} = \frac{1}{n} \sum_{k = 1}^n \sum_{l = 1}^n \omega^{(k - l)(j - 1)} m_{lk}.
\end{equation}
Analogously, taking $\conj{\m{F}} \m{D} \m{F}$ gives an $i,j$ element
\begin{eqnarray}
  (\m{C}_D)_{ij} & = & \conj{\m{F}} \m{D} \m{F} \nonumber \\
                 & = & \frac{1}{n^2} \sum_{l = 1}^n \sum_{k = 1}^n m_{lk} \conj{\ve{x}}_{k-l} \ve{x}_{i - j} \nonumber \\
                 & = & \frac{1}{n}  \sum_{l = 1}^n \sum_{k = 1}^n m_{lk} I \big ( (i - j) \equiv (k - l) \bmod n \big ) \label{eq:diagonalMeans}
\end{eqnarray}
where $I(A)$ is the indicator function which returns $1$ if $A$ is true and $0$ if $A$ is false.
Equation \ref{eq:diagonalMeans} indicates that $\m{C}_D$ is generated by replacing the values of $M$ along each circulant diagonal by the corresponding diagonal mean. Therefore $\m{C}_D = \m{T}_M$ when $\m{T}$ is restricted to be circulant. Therefore, $\m{C}_D$ is Frobenius optimal.

Though this fact has aleady been noted for $\m{M}$ Toeplitz by \cite{chan1988optimal} and more generally in \cite{venkatapathi2021circulant}, it is worth emphasizing here that it is a particular example of the more general result of Theorem \ref{thm:genOptimal}.

\subsection{Toeplitz matrices}

Two well-known examples of structural matrices are Toeplitz matrices and Hankel matrices. Toeplitz matrices have an index function
$$f(i,j) = j - i + n$$

\subsection{Hankel matrices}

Hankel matrices take
$$f(i,j) = i + j$$

\subsection{Toeplitz-plus-Hankel matrices}

Motivated by the use of multiple circulants to decompose a matrix in \cite{venkatapathi2021circulant} and their mention in \cite{yelim2016algorithms}, we might consider the sums of simpler structured matrices. Consider the case of a Toeplitz matrix and a Hankel matrix added together.

Our natural instinct for the index function in this case might just be the sum of previous index functions. That is
$$j - i + n + i + j = 2j + n,$$
but this is clearly incorrect as
$$a_{ij} = t_{j - i + n} + h_{i + j}$$
contains no equalities in $i,j$.
Rather, this describes a linear model of the entries with means removed according to both, as we are taking a difference
$$\m{T} + \m{H} - \m{M}$$
for $\m{T}$ Toeplitz and $\m{H}$ Hankel. \TODO{This needs to be expanded more...}

%% BIBLIOGRAPHY
\bibliographystyle{plain}
%\renewcommand*{\bibname}{References} % use title "References" for bibliography
\bibliography{../../Core/Bibliography/fullbib}

\end{document}
